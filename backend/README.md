# Backend for Open Australian Legal Corpus Explorer

## Getting Started

### Environment Setup

First we will need to setup the environment

By default, the application uses the Azure OpenAI API, if you wish to use OpenAI directly you can enable it in `app/settings.py`. 

Please use the following as an example `.env` file template which to place in this directory.

```
# The name of LLM model to use. Eg. gpt-4-0125-preview
MODEL=

# The Azure/OpenAI API key to use.
OPENAI_API_KEY=

# [Required for Azure OpenAI] OpenAI API model deployment endpoint. Eg. https://<autogeneratedurl>.openai.azure.com/
OPENAI_API_ENDPOINT=

# [Required for Azure OpenAI] OpenAI API version. Eg. 2024-02-15-preview
API_VERSION=

# Vector DB (currently Qdrant) host address. Eg. localhost
VECTOR_DB_HOST=172.17.0.1

# Vector DB (currently Qdrant) port. Eg. 6333
VECTOR_DB_PORT=6328

# Vector DB (currently Qdrant) collection name.
VECTOR_DB_COLLECTION=legal

# The address to start the backend app.
APP_HOST=0.0.0.0

# The port to start the backend app.
APP_PORT=8000

# Name of the embedding model to use.
EMBEDDING_MODEL=text-embedding-3-large

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
TOP_K=10

# Custom system prompt.
# Example:
# SYSTEM_PROMPT="
# We have provided context information below.
# ---------------------
# {context_str}
# ---------------------
# Given this information, please answer the question: {query_str}
# "
# SYSTEM_PROMPT="Aid the user based on their question: {query_str}"

```

### Python Setup

Second, set up the environment with poetry:

> **_Note:_** This step is not needed if you are using the dev-container.

```
poetry install
poetry shell
```

You can auto-populate the qdrant database with the corpus by running the below:

```
python app/engine/generate.py
```

Third, run the development server:

```
python main.py
```

To interact with the API, use the frontend or if you'd like to test the `/api/chat` endpoint:

```
curl --location 'localhost:8000/api/chat' \
--header 'Content-Type: application/json' \
--data '{ "messages": [{ "role": "user", "content": "Hello" }] }'
```

You may also open [http://localhost:8000/docs](http://localhost:8000/docs) with your browser to view the Swagger UI of the API.

CORS is allowed for all origins to simplify development. To adjust this for production environments, set the `ENVIRONMENT` environment variable to `prod`:

```
ENVIRONMENT=prod python main.py
```